{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrFnjcPwTETo"
   },
   "source": [
    "# CUSTOMER CHURN ANALYSIS AND CLASSIFICATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poRhm8nhTETu"
   },
   "source": [
    "## AIM\n",
    "\n",
    "With the rapid expansion of the telecom business, specialist co-ops are increasingly focusing on growing its endorser base. It has become a challenge to maintain existing clients in the difficult environment. It is stated that the cost of acquiring a new client is undoubtedly more than the cost of keeping the current one. As a result, telecom companies should use advanced analysis to figure out customer behaviour and, as a result, predict client relationships if they quit the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3l8Ldh3TETx"
   },
   "source": [
    "Some probable questions are as follows:\n",
    "\n",
    "\n",
    "a) What factors contribute to customer churn?\n",
    "\n",
    "b) Which customers are more likely to churn?\n",
    "\n",
    "c) What can be done to prevent them from leaving?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VecA8SW6TETy"
   },
   "source": [
    "## Overview\n",
    "1. Import data and python packages\n",
    "    * Import packages\n",
    "    * Import data\n",
    "    * Data shape and info\n",
    "2. Data visualization\n",
    "    * Count Plots\n",
    "    * Pie Plots\n",
    "    * Box Plots\n",
    "    * Heatmap(Correlation)\n",
    "    * Pairplot\n",
    "3. Classification\n",
    "\n",
    "    3.1 Split data as train and test \n",
    "    \n",
    "    3.2 Functions for models\n",
    "    \n",
    "    3.3 Models\n",
    "      * Decision Tree Classifier\n",
    "      * Gradient Booster Classifier\n",
    "      * KNN Classifier\n",
    "      * Random Forest Classifier\n",
    "      * Artificial Nural Network\n",
    "4. Result\n",
    "      * Cross validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7bmIKFKTETz"
   },
   "source": [
    "<a id=\"t1.\"></a>\n",
    "# 1. Import data and python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaKckN0zTET0",
    "outputId": "20ddf82c-e5b0-48b4-e0df-bf836def7dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mglearn\n",
      "  Obtaining dependency information for mglearn from https://files.pythonhosted.org/packages/bb/8b/687d30a3df6b870af541dde6327423e35713e38243db135f57b4ebd054f3/mglearn-0.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading mglearn-0.2.0-py2.py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: numpy in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (3.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (1.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (2.1.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (10.0.1)\n",
      "Requirement already satisfied: cycler in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (0.11.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (2.31.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\athir\\anaconda3\\lib\\site-packages (from mglearn) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from pandas->mglearn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from pandas->mglearn) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from scikit-learn->mglearn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from scikit-learn->mglearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\athir\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n",
      "Downloading mglearn-0.2.0-py2.py3-none-any.whl (581 kB)\n",
      "   ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/581.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/581.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/581.4 kB 220.2 kB/s eta 0:00:03\n",
      "   -- ------------------------------------ 41.0/581.4 kB 219.4 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 112.6/581.4 kB 547.6 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 286.7/581.4 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 399.4/581.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  573.4/581.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 581.4/581.4 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: mglearn\n",
      "Successfully installed mglearn-0.2.0\n"
     ]
    }
   ],
   "source": [
    "#installation of packages and libraries required\n",
    "!pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tce5eHGjTET2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix,accuracy_score, f1_score, precision_score, recall_score\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense , Activation\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#module and libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import mglearn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Machine Learning Models Diffrent Algorithms\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "AV0iuVKnTET3"
   },
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv('telecom_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HykfsNgHTET4",
    "outputId": "a36aff55-ac12-40f9-c4e5-a082e2dfe1c9"
   },
   "outputs": [],
   "source": [
    "# Show Data\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4eEhalyTET5",
    "outputId": "d5f143a0-bee1-42c8-e72c-d59e569e2f61"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'churn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Data shape\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m churn_df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'churn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Data shape\n",
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5VoOlGLTET5",
    "outputId": "dbc2502c-40b4-4c8c-acf4-7fc8cad84e47"
   },
   "outputs": [],
   "source": [
    "#Statistics based information of data\n",
    "churn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBVOKSSkTET6"
   },
   "source": [
    "> There are no null or missing data.\n",
    "\n",
    "> The attributes are of numeric type(int or float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "vvZWShxoTET6",
    "outputId": "e2494729-3c4b-4143-d367-6d08d030e9e4"
   },
   "outputs": [],
   "source": [
    "#Data Description\n",
    "churn_df_describe = churn_df.describe().T\n",
    "churn_df_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIoCPBXzTET6"
   },
   "source": [
    "Descriptive statistics for attributes of dataframe.\n",
    "- The count of each attribute represents no missing data anywhere.\n",
    "- The min and max values can be observed along with mean to analyze whether the outliers have impacted the mean or not.\n",
    "- Along with that, the percentiles are also given analyzing the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i7x0KoVTET7"
   },
   "source": [
    "\n",
    "### 2. Data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYQ3NjO6Bw8R"
   },
   "source": [
    "#### 2.1 Analysis of target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "kwedB48STET7",
    "outputId": "213c431f-edbe-49d2-886a-912c5f3de25b"
   },
   "outputs": [],
   "source": [
    "#churn feature as target\n",
    "labels = ['Churn', 'Not Churn']\n",
    "sizes = churn_df['Churn'].value_counts(sort = True)\n",
    "\n",
    "\n",
    "explode = (0.2, 0)\n",
    " \n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax1.pie(sizes, explode=explode, colors = [\"#FF6A6A\",\"#C2C4E2\"], labels=labels, autopct='%1.1f%%', shadow=True)\n",
    "ax1.axis('equal')\n",
    "\n",
    "plt.show()\n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R50LpizECZOb"
   },
   "source": [
    "Target labels interpretation:\n",
    "\n",
    "- 0 class: The customer will not leave the company service\n",
    "- 1 class: The customer will leave the company service\n",
    "\n",
    "\n",
    "More instances i.e almost 85% are of Churn category that means customer will leave the company on the basis of the attributes mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5K8LF5QhEvHM"
   },
   "source": [
    "#### 2.2 Analysis of attributes; Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "ane53TIHTET7",
    "outputId": "21a274c9-e5f0-4d50-9d67-bbb3d3cf7109"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(12,10))\n",
    "\n",
    "#Contract Renewal\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(data = churn_df , x = \"ContractRenewal\" ,palette=[\"lightgreen\",\"yellow\"], edgecolor='k')\n",
    "plt.title(\"Count Plot for attribute Contract Renewal\" , size=15, fontweight='bold', fontfamily='monospace')\n",
    "plt.xlabel(\"Contract Renewal\", size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel('')\n",
    "\n",
    "#DataPlan\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(data = churn_df , x = \"DataPlan\" , palette=[\"lightgreen\",\"yellow\"], edgecolor='k')\n",
    "plt.title(\"Count Plot for attribute Data Plan\" , size=15, fontweight='bold', fontfamily='monospace')\n",
    "plt.xlabel(\"Data Plan\", size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel('')\n",
    "\n",
    "#Customer Service Calls\n",
    "plt.subplot(2,2,(3,4))\n",
    "sns.countplot(data = churn_df , x = \"CustServCalls\" , palette=[\"lightgreen\",\"yellow\"], edgecolor='k')\n",
    "plt.title(\"Count Plot for attribute Customer Service Calls Renewal\" , size=15, fontweight='bold', fontfamily='monospace')\n",
    "plt.xlabel(\"Customer Service Calls Renewal\", size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn5FSgAWDiDr"
   },
   "source": [
    "Interpretation of Analysis:\n",
    "- **Contract Renewal**: Maximum cases are of churn where the factor is contract renewal. The services might have not been satisfiable.\n",
    "- **Data Plan**: On the basis of data plan service provided by the telecom company, the customers are more satisfied resulting in non-churn cases. Less than a half of customers didn't like the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf1Fo-sLFF-t"
   },
   "source": [
    "#### 2.3 Outliers detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "KJBHReoSTET8",
    "outputId": "35f1c6b8-fbe3-45d4-ae7c-564d4be7b0a4"
   },
   "outputs": [],
   "source": [
    "#AccountWeeks\n",
    "ax = plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxenplot(data = churn_df , y = \"AccountWeeks\" , x = \"Churn\" , color=\"#668B8B\", scale=\"linear\")\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"AccountWeeks\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#DataUsage\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxenplot(data = churn_df , y = \"DataUsage\" ,  x = \"Churn\" , color=\"#FF0000\", scale=\"linear\")\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"DataUsage\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#DayMins\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxenplot(data = churn_df , y = \"DayMins\" , x = \"Churn\" , color=\"#FF0000\", scale=\"linear\")\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"DayMins\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#DayCalls\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxenplot(data = churn_df , y = \"DayCalls\" , x = \"Churn\" , color=\"#668B8B\", scale=\"linear\")\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"DayCalls\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "cKx7AlsVTET8",
    "outputId": "4107c2bb-23c9-4921-bd82-d65f3dd878d1"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,8))\n",
    "\n",
    "#MonthlyCharge\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxenplot(data = churn_df , y = \"MonthlyCharge\" , x = \"Churn\" , palette=[\"#DC143C\",\"#458B00\"])\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"MonthlyCharge\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#OverageFee\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxenplot(data = churn_df , y = \"OverageFee\" , x = \"Churn\" ,palette=[\"#DC143C\",\"#458B00\"])\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"OverageFee\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#RoamMins\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxenplot(data = churn_df , y = \"RoamMins\" , x = \"Churn\" , palette=[\"#DC143C\",\"#458B00\"])\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"RoamMins\",size=13, fontweight='light', fontfamily='monospace')\n",
    "\n",
    "#CustServCalls\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxenplot(data = churn_df , y = \"CustServCalls\" , x = \"Churn\" , palette=[\"#DC143C\",\"#458B00\"])\n",
    "plt.xlabel(\"Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel(\"CustServCalls\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0THEekbGWsg"
   },
   "source": [
    "Analysis Interpretation:\n",
    "- The boxen plots of these four attributes show some outliers that are nearer to the min and max quartiles therefore, can be left untreated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-awTacVHIRo"
   },
   "source": [
    "#### 2.4 Paired Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "A6MZINpKTET9",
    "outputId": "aa811a98-3d18-455d-ae1b-786bf40b8569"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,5))\n",
    "churn_df.groupby(['ContractRenewal',\"DataPlan\"])['Churn'].mean().plot(figsize=(10,5),kind=\"bar\",color=\"#FF6347\",\n",
    "                                                               edgecolor='k')\n",
    "plt.title(\"Average Plot for Churn\" , size=18, fontweight='bold', fontfamily='monospace')\n",
    "plt.ylabel(\"ContractRenewal, DataPlan\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.xlabel(\"Average of Churn\",size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEH_5YrRTET-"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "Customer churn analysis requires the attributes ContractRenewal and DataPlan. The probability of customer churn is low if these two attributes are \"1\". DataPlan has a greater impact than ContractRenewal.\n",
    "\n",
    "By increasing DataUsage, customers are less likely to churn, and by decreasing other attributes, customers are also less likely to churn. This work has been done by classifying and averaging Churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V85oY_M9H1I8"
   },
   "source": [
    "#### 2.5 Basic Statistics about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "VMBZaNW1TET_",
    "outputId": "eac6e468-cbaf-4c5d-df0c-b34ee781dd42"
   },
   "outputs": [],
   "source": [
    "#mean corresponding to each attribute with churn(0 and 1)\n",
    "print(\"Churn:0 and Churn:1\")\n",
    "mean_df = churn_df.mean().reset_index()\n",
    "mean_df.columns = ['Feature', 'Mean']\n",
    "mean_df.set_index('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "u5UCmJEvTET_",
    "outputId": "e5b002b3-87e1-4575-db54-9af34a33764b"
   },
   "outputs": [],
   "source": [
    "#mean corresponding to each attriibute with churn(0)\n",
    "print(\"Churn:0\")\n",
    "mean_df = churn_df.loc[churn_df[\"Churn\"]==0].mean().reset_index()\n",
    "mean_df.columns = ['Feature', 'Mean']\n",
    "mean_df.set_index('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "m5iZbKjLTET_",
    "outputId": "5ab4659c-bcbd-49a9-a29b-2dbf9145b94f"
   },
   "outputs": [],
   "source": [
    "#mean corresponding to each attribute with churn(1)\n",
    "print(\"Churn:1\")\n",
    "mean_df = churn_df.loc[churn_df[\"Churn\"]==1].mean().reset_index()\n",
    "mean_df.columns = ['Feature', 'Mean']\n",
    "mean_df.set_index('Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGb8h5dNIJAF"
   },
   "source": [
    "#### 2.6 Attributes correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "s1C63NpTTEUA",
    "outputId": "7137bdf9-5ac5-493b-fe10-db89fe6293f9"
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "ax = plt.figure(figsize=(12,10))\n",
    "sns.heatmap(churn_df.corr(),annot=True,cmap=\"Blues\", fmt='.0%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhWYU8TfIR_s"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "Some features can be seen highly correlated with each other where the correlation present is greater than 50%. The dimensionality reduction can be performed to overcome this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "8eTjBTtaTEUA",
    "outputId": "c4fe4894-6f88-4726-c297-793e0877ca6b"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = churn_df[[\"DataUsage\",\"RoamMins\",\"DayMins\",\"MonthlyCharge\",\"Churn\",\"DayCalls\"]],\n",
    "            hue=\"Churn\", palette='Reds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiIC6TZWiTr0"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "The leptokurtic curve can be seen between identical features; observing the peak at curve where the class label is 0 i.e, the churn 0(not churn) category. The dataset/column values are spread evenly without much skewness. A dense cluster can be seen in each attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmBofPdfTEUA"
   },
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "dJKKaCwpTEUA",
    "outputId": "3908b9fd-2f0e-4c06-c6b5-027f663efc6f"
   },
   "outputs": [],
   "source": [
    "#Classification process overview\n",
    "mglearn.plots.plot_grid_search_overview();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzFjtE3nKTfM"
   },
   "source": [
    "### Data Scaling: Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkH2rfXJTEUC"
   },
   "outputs": [],
   "source": [
    "#scaling down values; standardizing\n",
    "scaler = StandardScaler().fit(churn_df.drop(\"Churn\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTDT7nfSTEUD"
   },
   "outputs": [],
   "source": [
    "#separation of dependent and independent variables\n",
    "X = scaler.transform(churn_df.drop(\"Churn\",axis=1))\n",
    "y = churn_df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mhcPDvJKM3O"
   },
   "source": [
    "### Dimensionality Reduction: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct4dp2UEJnMj"
   },
   "outputs": [],
   "source": [
    "#Reducing dimensions using principal component analysis\n",
    "pca = PCA(n_components=7)\n",
    "principalComponents = pca.fit(X)\n",
    "cumm_expainedvariance = np.cumsum(principalComponents.explained_variance_ratio_)\n",
    "principalComponents = pca.transform(X)\n",
    "principalComponents_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC'+str(i+1) for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "aWRnwVgyyZYb",
    "outputId": "7fc5bac3-68d6-4a5d-a029-c4e41447b30f"
   },
   "outputs": [],
   "source": [
    "#cummulative explained score corresponding to each principal component\n",
    "plt.bar(range(0,len(cumm_expainedvariance.tolist()[::-1])), cumm_expainedvariance, \n",
    "        alpha=0.5, align='center', edgecolor='black',label='Individual explained variance')\n",
    "\n",
    "plt.ylabel('Cummulative Explained variance ratio')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S62wf4wQfcbP"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "Plot representing the cummulative explained variance score that is the importance or important information each principal component carries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UpPLjrAxKAoY",
    "outputId": "d180d3f0-1967-4e73-b3d7-eecb3dc5e4ba"
   },
   "outputs": [],
   "source": [
    "#pca reduced dimension data\n",
    "principalComponents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7Dm1WZtTEUB"
   },
   "source": [
    "## 3.1. Split data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIaVR6qpLyOw"
   },
   "outputs": [],
   "source": [
    "#Storing dimensionally reduced data in variable denoted as independent feature variable\n",
    "X = principalComponents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCoIAw1BTEUE"
   },
   "outputs": [],
   "source": [
    "#splitting data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(principalComponents_df, y, test_size =0.20,random_state=0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFc_v4I-Lgpu",
    "outputId": "62bc0bd1-072f-4793-b3f0-54c95dc1e823"
   },
   "outputs": [],
   "source": [
    "#Shapes\n",
    "print(\"----Shapes of splitted training and test sets----\")\n",
    "print(\"Shape of Train X: \", X_train.shape)\n",
    "print(\"Shape of Train y: \", y_train.shape)\n",
    "print(\"Shape of Test X: \", X_test.shape)\n",
    "print(\"Shape of Test y: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxJNHBcbTEUE"
   },
   "source": [
    "\n",
    "## 3.2 Functions for models and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhPWTc-HTEUE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve,plot_confusion_matrix,accuracy_score,confusion_matrix\n",
    "\n",
    "#function for estimator\n",
    "def Model(model):\n",
    "    global X,y,X_train, X_test, y_train, y_test\n",
    "    print(type(model).__name__)\n",
    "    pred = model.predict(X_test)\n",
    "    acs = accuracy_score(y_test,pred)\n",
    "    print(\"Accuracy Score             :\",acs)\n",
    "    \n",
    "    plot_confusion_matrix(model,X,y,cmap=\"Reds\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXv5BVTnTEUE"
   },
   "outputs": [],
   "source": [
    "#function to plot ROC-AUC\n",
    "def Check(list_of_disp):\n",
    "    ax = plt.gca()\n",
    "    for i in list_of_disp: \n",
    "        i.plot(ax=ax)\n",
    "    plt.plot([0,1],[0,1],\"--\",color=\"k\",alpha=0.7)\n",
    "    plt.title(\"ROC Curve of Classifiers\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-V79PbBTEUF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#function to provide cross-validation score of estimator\n",
    "def CrossValidationScore(model_list):\n",
    "    global X,y\n",
    "    \n",
    "    mean_cross_val_score = []\n",
    "    model_name           = []\n",
    "    \n",
    "    for model in model_list:\n",
    "        model_name.append(type(model).__name__)\n",
    "        \n",
    "    for i in model_list:\n",
    "        scores = cross_val_score(i, X, y, cv=5)\n",
    "        mean_cross_val_score.append(scores.mean())\n",
    "        \n",
    "    cvs = pd.DataFrame({\"Model Name\":model_name,\"CVS\":mean_cross_val_score})\n",
    "    return cvs.style.background_gradient(\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltrtYmNGTEUF"
   },
   "source": [
    "<a id=\"t3.3\"></a>\n",
    "## 3.3 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=0, max_depth=4, min_samples_split=10)\n",
    "dt.fit(X_train, y_train)\n",
    "pd = dt.predict(X_test)\n",
    "plot_confusion_matrix(dt, X_test, y_test)\n",
    "\n",
    "#cm and roc\n",
    "dt_disp = plot_roc_curve(dt, X_test, y_test)\n",
    "plt.title(\"ROC Curve of {}\".format(type(dt).__name__))\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"k\",alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "#reults of DecisionTreeClassifier\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, dt.predict(X_test)))\n",
    "print(\"Precision Score: \", precision_score(y_test, dt.predict(X_test)))\n",
    "print(\"Recall Score: \", recall_score(y_test, dt.predict(X_test)))\n",
    "print(\"F1 Score: \",f1_score(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(n_estimators=200, max_depth=2, random_state=0)\n",
    "gb.fit(X_train, y_train)\n",
    "pg = gb.predict(X_test)\n",
    "plot_confusion_matrix(gb, X_test, y_test) \n",
    "\n",
    "#cm and roc\n",
    "gb_disp = plot_roc_curve(gb, X_test, y_test)\n",
    "plt.title(\"ROC Curve of {}\".format(type(gb).__name__))\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"k\",alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "#reults of knn\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, gb.predict(X_test)))\n",
    "print(\"Precision Score: \", precision_score(y_test, gb.predict(X_test)))\n",
    "print(\"Recall Score: \", recall_score(y_test, gb.predict(X_test)))\n",
    "print(\"F1 Score: \",f1_score(y_test, gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHUQrtiMTEUF"
   },
   "source": [
    "#### 3.3.3. K NEIGHBORS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "SYLuwuUETEUG",
    "outputId": "6e9e88e6-d531-456c-d24a-3d002e1660b3"
   },
   "outputs": [],
   "source": [
    "#searching for optimal k value by observing results/score at each k; k=1 to 29\n",
    "k_max = 30\n",
    "accuracy = [[],[]]\n",
    "for k in range(1,k_max+1):\n",
    "    mdl = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "    pred = mdl.predict(X_test)\n",
    "    accuracy[0].append(k)\n",
    "    accuracy[1].append(accuracy_score(y_test, pred)) \n",
    "accuracy = np.array(accuracy)\n",
    "max_acc_k = accuracy[1].argmax()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(accuracy[0],accuracy[1], color='k', ls=\"--\")\n",
    "plt.scatter(x=accuracy[0][max_acc_k], y=accuracy[1][max_acc_k],s=50, label=\"Max Accuracy: {}\\nBest K: {}\".format(round(accuracy[1][max_acc_k],2),\n",
    "                                                                                                 accuracy[0][max_acc_k]), color='#ffb3b3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Accuracy Score for each K\" , size=18, fontweight='bold', fontfamily='monospace')\n",
    "plt.xlabel(\"K\", size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.ylabel('Accuracy Score', size=13, fontweight='light', fontfamily='monospace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkXnUhZljN6b"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "The best K value has come out to be 5 with maximum accuracy score achieved as 92.0 at this particular K. Increase in value of K, further, leads to decrease in accuracy score reflecting not to choose higher K value to prevent a huge degradation in performance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "FSq_tseXTEUG",
    "outputId": "fc4b049e-55ff-495a-8bc5-f65dc3d5b948"
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train,y_train)\n",
    "print(\"Model Installed!\")\n",
    "print(\"Please Wait for Results..\")\n",
    "Model(knn)\n",
    "\n",
    "#cm and roc\n",
    "knn_disp = plot_roc_curve(knn, X_test, y_test)\n",
    "plt.title(\"ROC Curve of {}\".format(type(knn).__name__))\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"k\",alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "#reults of knn\n",
    "print(\"Precision Score: \", precision_score(y_test, knn.predict(X_test)))\n",
    "print(\"Recall Score: \", recall_score(y_test, knn.predict(X_test)))\n",
    "print(\"F1 Score: \",f1_score(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4. RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "print(\"Model Installed!\")\n",
    "print(\"Please Wait for Results..\")\n",
    "Model(rf)\n",
    "\n",
    "rf_disp = plot_roc_curve(rf, X_test, y_test)\n",
    "plt.title(\"ROC Curve of {}\".format(type(rf).__name__))\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"k\",alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "#results of RF\n",
    "print(\"Precision Score: \", precision_score(y_test, rf.predict(X_test)))\n",
    "print(\"Recall Score: \", recall_score(y_test, rf.predict(X_test)))\n",
    "print(\"F1 Score: \",f1_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ROC-AUC of knn and RF\n",
    "list_of_disp = [knn_disp,rf_disp]\n",
    "Check(list_of_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "The model with the highest Accuracy Score is Random Forest Classifier. At the same time, when looking at the ROC curve of Random Forest Classifier, it is seen that it learns the classes better than other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjJk9DBKTEUG"
   },
   "source": [
    "#### 3.3.5. ARTIFICIAL NEURAL NETWORK\n",
    "##### Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEyWqd4xTEUG"
   },
   "outputs": [],
   "source": [
    "#y data to categorical form\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zcb6X0UTEUH"
   },
   "outputs": [],
   "source": [
    "# ANN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,input_shape=X_train[0].shape,activation=\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OQUy1fbTEUH",
    "outputId": "a4e829ed-14a7-46d8-e295-da41baa0f54a"
   },
   "outputs": [],
   "source": [
    "#fitting the network\n",
    "history = model.fit(X_train,y_train_cat,batch_size=32,epochs=20,validation_data=(X_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "j5J0_1I3TEUH",
    "outputId": "0f1c54d8-b509-4ccd-c4ac-b411b2ee274a"
   },
   "outputs": [],
   "source": [
    "#performance visuals of ANN\n",
    "\n",
    "#Accuracy\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"acc\"],color=\"#C2C4E2\")\n",
    "plt.plot(history.history[\"val_acc\"],color=\"#ffb3b3\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.legend([\"Training\",\"Validation\"])\n",
    "plt.grid()\n",
    "\n",
    "#loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"],color=\"#C2C4E2\")\n",
    "plt.plot(history.history[\"val_loss\"],color=\"#ffb3b3\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Training\",\"Validation\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXSrpFr5kMLw"
   },
   "source": [
    "**Interpretation of Analysis:**\n",
    "\n",
    "The plots plotted above has shown the accuracy and loss at each epoch compiled during the fitting of neural network; both during training and validation.\n",
    "\n",
    "- The accuracy during training and validation chasing each other with a similar pace, resulting in average accuracy as 91 and 93 on training and validation respectively.\n",
    "- The loss during training and validation is moving towards the deepest value, resulting in least average loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zj4bjlBUlGI9",
    "outputId": "fcbd9e8a-1254-4f7c-ec99-e9f763e05e75"
   },
   "outputs": [],
   "source": [
    "#evaluation score on test set\n",
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOAPSxFcTEUH",
    "outputId": "9f36dc1f-7c82-401e-ce00-b7b3856ea2e7"
   },
   "outputs": [],
   "source": [
    "#probabilistic output to class output conversion\n",
    "pred_class = model.predict(X_test)\n",
    "\n",
    "def toClass(pred):   \n",
    "    class_ = np.zeros(len(pred))\n",
    "    for i in range(len(pred)):\n",
    "        index = pred[i].argmax()\n",
    "        class_[i] = index\n",
    "        \n",
    "    return class_\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(toClass(y_test_cat),toClass(pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf5taPj_mvFE",
    "outputId": "8aa5f237-9d08-4273-e1c2-71398511b162"
   },
   "outputs": [],
   "source": [
    "#reults of ANN\n",
    "print(\"Accuracy Score: \", accuracy_score(toClass(y_test_cat),toClass(pred_class)))\n",
    "print(\"Precision Score: \", precision_score(toClass(y_test_cat),toClass(pred_class)))\n",
    "print(\"Recall Score: \", recall_score(toClass(y_test_cat),toClass(pred_class)))\n",
    "print(\"F1 Score: \",f1_score(toClass(y_test_cat),toClass(pred_class)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShPPr0FnTEUK"
   },
   "source": [
    "# 4. Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unACu6iVTEUK"
   },
   "source": [
    "#### CROSS VALIDATION SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "SfsFPxDLTEUK",
    "outputId": "19c861a1-e9a7-4f1d-d259-fe4849fd9950"
   },
   "outputs": [],
   "source": [
    "#Overview of cross validation score structure\n",
    "mglearn.plots.plot_cross_validation();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "v8F4NlFFTEUK",
    "outputId": "35e12779-8ad1-42c9-dfa0-0c977c6849aa"
   },
   "outputs": [],
   "source": [
    "#cross validation score achieved by model\n",
    "from sklearn import svm\n",
    "model = svm.SVC()\n",
    "accuracy = cross_val_score(model, X, y, scoring='accuracy', cv = 10)\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "C2RWlWWxj_R9",
    "outputId": "236a994b-4afe-4074-94b1-cab58c6158d9"
   },
   "outputs": [],
   "source": [
    "#performance plots\n",
    "ax = plt.figure(figsize=(12,8))\n",
    "\n",
    "#accuracy\n",
    "plt.subplot(2,2,1)\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(['Decision Tree', 'Gradient Boosting', 'KNN', 'Random Forest', 'ANN'],\n",
    "[accuracy_score(y_test, dt.predict(X_test)),\n",
    "accuracy_score(y_test, gb.predict(X_test)),\n",
    "accuracy_score(y_test, knn.predict(X_test)),\n",
    "accuracy_score(y_test, rf.predict(X_test)),\n",
    "accuracy_score(toClass(y_test_cat),toClass(pred_class))], palette=[\"#20B2AA\",\"#87CEFA\",\"#B0E2FF\", \"#A4D3EE\", \"#8DB6CD\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "#precision\n",
    "plt.subplot(2,2,2)\n",
    "sns.barplot(['Decision Tree', 'Gradient Boosting', 'KNN', 'Random Forest', 'ANN'],\n",
    "[precision_score(y_test, dt.predict(X_test)),\n",
    "precision_score(y_test, gb.predict(X_test)),\n",
    "precision_score(y_test, knn.predict(X_test)),\n",
    "precision_score(y_test, rf.predict(X_test)),\n",
    "precision_score(toClass(y_test_cat),toClass(pred_class))], palette=[\"#20B2AA\",\"#87CEFA\",\"#B0E2FF\", \"#A4D3EE\", \"#8DB6CD\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Precision Score\")\n",
    "\n",
    "#recall\n",
    "plt.subplot(2,2,3)\n",
    "sns.barplot(['Decision Tree', 'Gradient Booster', 'KNN', 'Random Forest', 'ANN'],\n",
    "[recall_score(y_test, dt.predict(X_test)),\n",
    "recall_score(y_test, gb.predict(X_test)),\n",
    "recall_score(y_test, knn.predict(X_test)),\n",
    "recall_score(y_test, rf.predict(X_test)),\n",
    "recall_score(toClass(y_test_cat),toClass(pred_class))], palette=[\"#20B2AA\",\"#87CEFA\",\"#B0E2FF\", \"#A4D3EE\", \"#8DB6CD\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Recall Score\")\n",
    "\n",
    "#f1score\n",
    "plt.subplot(2,2,4)\n",
    "sns.barplot(['Decision Tree', 'Gradient Boosting', 'KNN', 'Random Forest', 'ANN'],\n",
    "[f1_score(y_test, dt.predict(X_test)),\n",
    "f1_score(y_test, gb.predict(X_test)),\n",
    "f1_score(y_test, knn.predict(X_test)),\n",
    "f1_score(y_test, rf.predict(X_test)),\n",
    "f1_score(toClass(y_test_cat),toClass(pred_class))], palette=[\"#20B2AA\",\"#87CEFA\",\"#B0E2FF\", \"#A4D3EE\", \"#8DB6CD\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzAloJgF76Bx"
   },
   "source": [
    "### **Interpretation of Results:**\n",
    "\n",
    "After all the experimentation and analysis, the conclusion that comes out is ANN and Random Forest have worked so well from the beginning to the last and have classified the churn category with least error. \n",
    "\n",
    "Overall report of all models\n",
    "--------------------------------------\n",
    "\n",
    "**Decision Tree:**\n",
    "\n",
    "- Accuracy Score:  0.9175412293853074\n",
    "- Precision Score:  0.7916666666666666\n",
    "- Recall Score:  0.5876288659793815\n",
    "- F1 Score:  0.6745562130177515\n",
    "\n",
    "\n",
    "**Gradient Boosting:**\n",
    "\n",
    "- Accuracy Score:  0.9220389805097451\n",
    "- Precision Score:  0.8461538461538461\n",
    "- Recall Score:  0.5670103092783505\n",
    "- F1 Score:  0.6790123456790124\n",
    "\n",
    "\n",
    "**KNN:**\n",
    "\n",
    "- Cross-validation-Score:\t0.900690\n",
    "- Accuracy Score: 0.9160419790104948\n",
    "- Precision Score:  0.8727272727272727\n",
    "- Recall Score:  0.4948453608247423\n",
    "- F1 Score:  0.6315789473684211\n",
    "\n",
    "**Random Forest:**\n",
    "\n",
    "- Cross-validation-Score:\t0.917195\n",
    "- Accuracy Score: 0.9310344827586207\n",
    "- Precision Score:  0.8695652173913043\n",
    "- Recall Score:  0.6185567010309279\n",
    "- F1 Score:  0.7228915662650603\n",
    "\n",
    "**ANN:**\n",
    "\n",
    "- Accuracy Score: 0.9355322338830585\n",
    "- Precision Score: 0.9090909090909091\n",
    "- Recall Score: 0.6185567010309279\n",
    "- F1 Score: 0.7361963190184049\n",
    "\n",
    " \n",
    "### **CONCLUSION**\n",
    "\n",
    "The score of **Artificial Neural Network and Random Forest Classifier** in classifying the customer churn has been observed more active and accurate resulting in best estimators for such cases. Also, the KNN has been seen chasing both other classifiers with competitive scores but lagged behind with few percent declining the accuracy, but cannot be ignored for future improvements. Comparison between both shows, the **Artificial Neural Network(ANN)** is having greater precision score as well as F1-score which reflects its fine behavior in identifying the classes and predicting them positively with any fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "customer_churn_analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
